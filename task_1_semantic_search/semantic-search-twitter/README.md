# ğŸ” Semantic Search for Twitter API Documentation

A beginner-friendly Python project to search Twitter API documentation using semantic embeddings and FAISS vector search.

## ğŸ“‹ Features

- **Document Chunking**: Splits markdown files into meaningful chunks
- **Embeddings**: Uses SentenceTransformers for semantic embeddings
- **Vector Search**: FAISS-based similarity search
- **CLI Interface**: Command-line query interface
- **Metadata Tracking**: Keeps track of document sources

## ğŸ›  Setup

### Prerequisites
- Python 3.8 or higher
- pip package manager

### Installation

1. **Clone/Navigate to project**
```bash
cd semantic-search-twitter
```

2. **Create virtual environment**
```bash
python -m venv venv
source venv/bin/activate  # Mac/Linux
# OR
venv\Scripts\activate     # Windows
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

4. **Add your data**
```bash
# Place Twitter API markdown files in:
data/raw_docs/
```

## ğŸš€ Usage

### Basic Search
```bash
python semantic_search.py --query "how to fetch tweets"
```

### Advanced Options
```bash
python semantic_search.py --query "authentication" --top-k 5 --rebuild-index
```

### Command-line Arguments
- `--query TEXT`: Search query (required)
- `--top-k INT`: Number of results to return (default: 3)
- `--rebuild-index`: Force rebuild of embeddings index

## ğŸ“ Project Structure

```
semantic-search-twitter/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw_docs/              # Place markdown files here
â”œâ”€â”€ embeddings/
â”‚   â”œâ”€â”€ index.faiss            # Vector index (auto-generated)
â”‚   â””â”€â”€ metadata.json          # Chunk metadata (auto-generated)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ chunker.py             # Document chunking logic
â”‚   â”œâ”€â”€ embedder.py            # Embedding generation
â”‚   â”œâ”€â”€ indexer.py             # FAISS index management
â”‚   â”œâ”€â”€ search.py              # Search implementation
â”‚   â””â”€â”€ utils.py               # Helper functions
â”œâ”€â”€ semantic_search.py         # Main CLI entry point
â”œâ”€â”€ requirements.txt           # Project dependencies
â”œâ”€â”€ README.md                  # This file
â””â”€â”€ .gitignore                 # Git ignore rules
```

## ğŸ“š Project Files Explanation

| File | Purpose |
|------|---------|
| `src/chunker.py` | Loads markdown files and splits them into chunks |
| `src/embedder.py` | Converts text chunks into vector embeddings |
| `src/indexer.py` | Creates and manages FAISS vector index |
| `src/search.py` | Performs semantic similarity search |
| `src/utils.py` | Utility functions (file I/O, logging, etc.) |
| `semantic_search.py` | Main entry point for CLI application |

## ğŸ”„ Workflow

1. **Load Documents** â†’ `src/chunker.py` reads all markdown files
2. **Create Chunks** â†’ Documents split into meaningful segments
3. **Generate Embeddings** â†’ `src/embedder.py` creates vector representations
4. **Build Index** â†’ `src/indexer.py` stores in FAISS
5. **Search** â†’ User queries matched against index
6. **Return Results** â†’ Top-K similar chunks ranked by similarity

## ğŸ¯ Next Steps

1. Add your Twitter API documentation markdown files to `data/raw_docs/`
2. Run `python semantic_search.py --query "test"` to build the index
3. Try different queries to test the search
4. Iterate on the code to improve results

## ğŸ“ Notes for Beginners

- Start simple: build one module at a time
- Test each piece independently
- Use print statements to debug
- Read the docstrings in each module
- Gradually add complexity (caching, filtering, etc.)

## ğŸ¤ Common Issues & Solutions

**Issue**: ImportError for faiss or sentence-transformers
```bash
# Solution: Make sure virtual environment is activated
source venv/bin/activate
pip install -r requirements.txt
```

**Issue**: No documents found in `data/raw_docs/`
```bash
# Solution: Add markdown files to the folder first
ls data/raw_docs/  # Check if files exist
```

**Issue**: Out of memory with large documents
```bash
# Solution: Adjust chunk size in src/chunker.py
```

## ğŸ“– Learning Resources

- [FAISS Documentation](https://faiss.ai/)
- [Sentence-Transformers](https://www.sbert.net/)
- [Semantic Search Concepts](https://huggingface.co/docs/transformers/tasks/semantic_similarity)

## âš–ï¸ License

MIT License
